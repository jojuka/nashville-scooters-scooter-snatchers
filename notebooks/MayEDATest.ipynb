{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6711db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfc77ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 790 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubdatetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sumdid</th>\n",
       "      <th>sumdtype</th>\n",
       "      <th>chargelevel</th>\n",
       "      <th>sumdgroup</th>\n",
       "      <th>costpermin</th>\n",
       "      <th>companyname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01:41.2</td>\n",
       "      <td>36.136822</td>\n",
       "      <td>-86.799877</td>\n",
       "      <td>PoweredLIRL1</td>\n",
       "      <td>Powered</td>\n",
       "      <td>93</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01:41.2</td>\n",
       "      <td>36.191252</td>\n",
       "      <td>-86.772945</td>\n",
       "      <td>PoweredXWRWC</td>\n",
       "      <td>Powered</td>\n",
       "      <td>35</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01:41.2</td>\n",
       "      <td>36.144752</td>\n",
       "      <td>-86.806293</td>\n",
       "      <td>PoweredMEJEH</td>\n",
       "      <td>Powered</td>\n",
       "      <td>90</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01:41.2</td>\n",
       "      <td>36.162056</td>\n",
       "      <td>-86.774688</td>\n",
       "      <td>Powered1A7TC</td>\n",
       "      <td>Powered</td>\n",
       "      <td>88</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01:41.2</td>\n",
       "      <td>36.150973</td>\n",
       "      <td>-86.783109</td>\n",
       "      <td>Powered2TYEF</td>\n",
       "      <td>Powered</td>\n",
       "      <td>98</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pubdatetime   latitude  longitude        sumdid sumdtype  chargelevel  \\\n",
       "0     01:41.2  36.136822 -86.799877  PoweredLIRL1  Powered           93   \n",
       "1     01:41.2  36.191252 -86.772945  PoweredXWRWC  Powered           35   \n",
       "2     01:41.2  36.144752 -86.806293  PoweredMEJEH  Powered           90   \n",
       "3     01:41.2  36.162056 -86.774688  Powered1A7TC  Powered           88   \n",
       "4     01:41.2  36.150973 -86.783109  Powered2TYEF  Powered           98   \n",
       "\n",
       "  sumdgroup  costpermin companyname  \n",
       "0   scooter           0        Bird  \n",
       "1   scooter           0        Bird  \n",
       "2   scooter           0        Bird  \n",
       "3   scooter           0        Bird  \n",
       "4   scooter           0        Bird  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "may = pd.read_csv('../data/may.csv')\n",
    "may.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58e9620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   pubdatetime  1048575 non-null  object \n",
      " 1   latitude     1048575 non-null  float64\n",
      " 2   longitude    1048575 non-null  float64\n",
      " 3   sumdid       1048575 non-null  object \n",
      " 4   sumdtype     1048575 non-null  object \n",
      " 5   chargelevel  1048575 non-null  int64  \n",
      " 6   sumdgroup    1048575 non-null  object \n",
      " 7   costpermin   1048575 non-null  int64  \n",
      " 8   companyname  1048575 non-null  object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 72.0+ MB\n"
     ]
    }
   ],
   "source": [
    "may.info() ##20292503 rows, 9 columns, note pubdatetime is an object and needs to be changed to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0806dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pubdatetime    0\n",
       "latitude       0\n",
       "longitude      0\n",
       "sumdid         0\n",
       "sumdtype       0\n",
       "chargelevel    0\n",
       "sumdgroup      0\n",
       "costpermin     0\n",
       "companyname    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may.isnull().sum()##CHARGE LEVEL COLUMN HAS 283 NULLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1bf990",
   "metadata": {},
   "outputs": [],
   "source": [
    "##may.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f002b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "##may.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22027dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bird', 'Lyft', 'Gotcha', 'Lime'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may.companyname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cf4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_dict = {'Bird':'Bi', 'Lyft': 'Ly', 'Gotcha': 'G', 'Lime': 'Li', 'Spin': 'S', 'Jump': 'J', 'Bolt': 'Bo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2add0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "may.companyname = may.companyname.replace(company_dict)##replaced company name with 2 letter name dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422a1847",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "hour must be in 0..23: 24:00.0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36m_build_naive\u001b[1;34m(self, res, default)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0mnaive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: hour must be in 0..23",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParserError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: hour must be in 0..23: 24:00.0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid string coercion to datetime",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36m_build_naive\u001b[1;34m(self, res, default)\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0mnaive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: hour must be in 0..23",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10864/1548635655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpubdatetime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpubdatetime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m##CHANGES PUBDATETIME COLUMN FROM OBJECT TO DATE TIME\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mcache_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mutc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"utc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     result, tz_parsed = objects_to_datetime64ns(\n\u001b[0m\u001b[0;32m    402\u001b[0m         \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz_parsed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2193\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtz_parsed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py\u001b[0m in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[0;32m   2173\u001b[0m     \u001b[0morder\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"F\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"C\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m         result, tz_parsed = tslib.array_to_datetime(\n\u001b[0m\u001b[0;32m   2176\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\dateutil\\parser\\_parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_naive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParserError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignoretz\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: hour must be in 0..23: 24:00.0"
     ]
    }
   ],
   "source": [
    "may.pubdatetime = pd.to_datetime(may.pubdatetime)##CHANGES PUBDATETIME COLUMN FROM OBJECT TO DATE TIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52be642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6136f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5620422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##maypubdatetime = pd.to_datetime(may.pubdatetime)##CHANGES PUBDATETIME COLUMN FROM OBJECT TO DATE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "may.sumdgroup.unique() ##produces all the unique values in the sumdgroup column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "may.sumdtype.unique() ##produces all the unique values in the sumdtype column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters = may.loc[may.sumdgroup.isin(['scooter', 'Scooter'])] ##FILTERS DATAFRAME TO ONLY SHOW ROWS WHERE SUMDGROUP = SCOOTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.companyname.value_counts() ##gives the count of scooters by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb46bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters = may_scooters[['pubdatetime', 'latitude', 'longitude', 'sumdid', 'chargelevel', 'companyname']] ##drops columns costpermin from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##may_scooters = may_scooters.drop(columns=['costpermin']) ##drops columns chargelevel and costpermin from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.dropna(inplace=True) ##dropping all null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.info()\n",
    "##Original info before drop of null rows, RangeIndex: 20292503 entries, 0 to 20292502, Data columns (total 9 columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7eb8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.to_pickle(\"../data/may.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaca2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "may_test = pd.read_pickle(\"../data/may.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.sumdid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.sumdid.nunique() ##count the number of unique sumdid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ac726",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(may_scooters['sumdid'].value_counts()) ##the count of each of the distinct values of a specific column\n",
    "##https://datascienceparichay.com/article/pandas-count-of-unique-values-in-each-column/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##7 SCOOTER COMPANIES, 8304 SCOOTERS, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beed043",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_group=may_scooters.groupby(['companyname'])['sumdid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ba781",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import matplotlib.pyplot as plt\n",
    "##import seaborn as sns\n",
    "##%matplotlib inline      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc44562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the seaborn theme, style, color palette\n",
    "#sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "#make a correlation plot that looks at each variables relationship with every other variable\n",
    "#and plots the distribution of each variable along the diagonal\n",
    "#sns.pairplot(may_scooters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = may_scooters[may_scooters.duplicated()]\n",
    "## Select duplicate rows except first occurrence based on all columns\n",
    "##duplicateRowsDF = dfObj[dfObj.duplicated()]\n",
    "##print(\"Duplicate Rows except first occurrence based on all columns are :\")\n",
    "##print(duplicateRowsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc629c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicate Rows except first occurrence based on all columns are:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828242ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://thispointer.com/pandas-find-duplicate-rows-in-a-dataframe-based-on-all-or-selected-columns-using-dataframe-duplicated-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ad69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##may_scooters['chargelevel']==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d27e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_dead=may_scooters.loc[(may_scooters['chargelevel'] == 0.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae28a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "may_dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa552088",
   "metadata": {},
   "outputs": [],
   "source": [
    "Powered406=may_dead.loc[(may_dead['sumdid']=='Powered406')]\n",
    "Powered406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all duplicate rows based on multiple column names in list\n",
    "duplicate_location = Powered406[Powered406.duplicated(['latitude', 'longitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea58f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_location ##in Powered406 there are 868 rows. when looking at duplicate locations for Powered406 662 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb2ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab1968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f302834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
