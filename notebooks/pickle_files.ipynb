{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with a large dataset on your computer** is a common challenge for data analysts. If you need to process or filter the data you can set the `chunksize=` argument of pandas `read_csv()` method to loop through and work with manageable chunks of the data.\n",
    "\n",
    "If for example, you wanted to work with a large data file (HCPS_data.csv) to pull just the rows where the `HCPS Code` is **99213**, you could read that file to a chunk of 100,000 rows at a time, filter each chunk to the rows with the specified code, save the filtered results of each chunk to a list and concatenate them all together at the end. The syntax would look something like this:\n",
    "\n",
    "```\n",
    "code_99213_rows =[]\n",
    "\n",
    "for chunk in pd.read_csv('HCPS_data.csv', chunksize = 100000):\n",
    "    code_99213_rows.append(chunk[chunk['HCPS Code'] == '99213']) \n",
    "               \n",
    "code_99213_df = pd.concat(code_99213_rows, ignore_index=True)\n",
    "```\n",
    "======================================================================   \n",
    "\n",
    "To shrink the size of a file so that it loads more quickly, converting a text file (CSV) to binary might make sense. In python, you can work with data to minimize its footprint and then store the resulting object (dataframe) as a [pickle](https://docs.python.org/3/library/pickle.html) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubdatetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sumdid</th>\n",
       "      <th>sumdtype</th>\n",
       "      <th>chargelevel</th>\n",
       "      <th>sumdgroup</th>\n",
       "      <th>costpermin</th>\n",
       "      <th>companyname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01 00:01:41.247000</td>\n",
       "      <td>36.136822</td>\n",
       "      <td>-86.799877</td>\n",
       "      <td>PoweredLIRL1</td>\n",
       "      <td>Powered</td>\n",
       "      <td>93.0</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-01 00:01:41.247000</td>\n",
       "      <td>36.191252</td>\n",
       "      <td>-86.772945</td>\n",
       "      <td>PoweredXWRWC</td>\n",
       "      <td>Powered</td>\n",
       "      <td>35.0</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-01 00:01:41.247000</td>\n",
       "      <td>36.144752</td>\n",
       "      <td>-86.806293</td>\n",
       "      <td>PoweredMEJEH</td>\n",
       "      <td>Powered</td>\n",
       "      <td>90.0</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-01 00:01:41.247000</td>\n",
       "      <td>36.162056</td>\n",
       "      <td>-86.774688</td>\n",
       "      <td>Powered1A7TC</td>\n",
       "      <td>Powered</td>\n",
       "      <td>88.0</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-01 00:01:41.247000</td>\n",
       "      <td>36.150973</td>\n",
       "      <td>-86.783109</td>\n",
       "      <td>Powered2TYEF</td>\n",
       "      <td>Powered</td>\n",
       "      <td>98.0</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pubdatetime   latitude  longitude        sumdid sumdtype  \\\n",
       "0  2019-05-01 00:01:41.247000  36.136822 -86.799877  PoweredLIRL1  Powered   \n",
       "1  2019-05-01 00:01:41.247000  36.191252 -86.772945  PoweredXWRWC  Powered   \n",
       "2  2019-05-01 00:01:41.247000  36.144752 -86.806293  PoweredMEJEH  Powered   \n",
       "3  2019-05-01 00:01:41.247000  36.162056 -86.774688  Powered1A7TC  Powered   \n",
       "4  2019-05-01 00:01:41.247000  36.150973 -86.783109  Powered2TYEF  Powered   \n",
       "\n",
       "   chargelevel sumdgroup  costpermin companyname  \n",
       "0         93.0   scooter         0.0        Bird  \n",
       "1         35.0   scooter         0.0        Bird  \n",
       "2         90.0   scooter         0.0        Bird  \n",
       "3         88.0   scooter         0.0        Bird  \n",
       "4         98.0   scooter         0.0        Bird  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "may = pd.read_csv('../data/may.csv')\n",
    "may.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try to reduce the size of the file\n",
    "- objects require the most space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20292503 entries, 0 to 20292502\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   pubdatetime  object \n",
      " 1   latitude     float64\n",
      " 2   longitude    float64\n",
      " 3   sumdid       object \n",
      " 4   sumdtype     object \n",
      " 5   chargelevel  float64\n",
      " 6   sumdgroup    object \n",
      " 7   costpermin   float64\n",
      " 8   companyname  object \n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 1.4+ GB\n"
     ]
    }
   ],
   "source": [
    "may.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert the company name to an integer \n",
    "- find the unique company names\n",
    "- assign each company an integer (you can use a dictionary for this step)\n",
    "- update the `companyname` column to store the integer id for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bird', 'Lyft', 'Gotcha', 'Lime', 'Spin', 'Jump', 'Bolt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may.companyname.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_dict = {'Bird':0, 'Lyft': 1, 'Gotcha': 2, 'Lime': 3, 'Spin': 4, 'Jump': 5, 'Bolt': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "may.companyname = may.companyname.replace(company_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### next convert `pubdatetime` to a datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubdatetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sumdid</th>\n",
       "      <th>sumdtype</th>\n",
       "      <th>chargelevel</th>\n",
       "      <th>sumdgroup</th>\n",
       "      <th>costpermin</th>\n",
       "      <th>companyname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01 00:01:41.247</td>\n",
       "      <td>36.136822</td>\n",
       "      <td>-86.799877</td>\n",
       "      <td>PoweredLIRL1</td>\n",
       "      <td>Powered</td>\n",
       "      <td>93.0</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-01 00:01:41.247</td>\n",
       "      <td>36.191252</td>\n",
       "      <td>-86.772945</td>\n",
       "      <td>PoweredXWRWC</td>\n",
       "      <td>Powered</td>\n",
       "      <td>35.0</td>\n",
       "      <td>scooter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pubdatetime   latitude  longitude        sumdid sumdtype  \\\n",
       "0 2019-05-01 00:01:41.247  36.136822 -86.799877  PoweredLIRL1  Powered   \n",
       "1 2019-05-01 00:01:41.247  36.191252 -86.772945  PoweredXWRWC  Powered   \n",
       "\n",
       "   chargelevel sumdgroup  costpermin  companyname  \n",
       "0         93.0   scooter         0.0            0  \n",
       "1         35.0   scooter         0.0            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may.pubdatetime = pd.to_datetime(may.pubdatetime)\n",
    "may.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next remove unneeded data\n",
    "#### keep just the scooters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['scooter', 'Scooter', 'bicycle'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may.sumdgroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters = may.loc[may.sumdgroup.isin(['scooter', 'Scooter'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keep just the columns we want to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "may_scooters = may_scooters[['pubdatetime', 'latitude', 'longitude', 'sumdid', 'chargelevel', 'companyname']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check `.info()` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20283582 entries, 0 to 20292502\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   pubdatetime  datetime64[ns]\n",
      " 1   latitude     float64       \n",
      " 2   longitude    float64       \n",
      " 3   sumdid       object        \n",
      " 4   chargelevel  float64       \n",
      " 5   companyname  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(1)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "may_scooters.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The only object datatype remaining is sumdid (an alphanumeric unique identifier)\n",
    "- time to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/may.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_105964/4081725100.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmay_scooters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/may.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[0;32m   2955\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2957\u001b[1;33m         to_pickle(\n\u001b[0m\u001b[0;32m   2958\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[1;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geospatial\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/may.pkl'"
     ]
    }
   ],
   "source": [
    "may_scooters.to_pickle(\"data/may.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "may_test = pd.read_pickle(\"data/may.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
